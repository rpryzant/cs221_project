

==== DIRECTORY STRUCTURE AND FILES

./
   main.py  -- driver code for running games and agents

   Makefile -- makefile

   final.pdf -- writeup

   analysis/
      convergence_rate/ -- code and data for fig. 4
      features_learning_rates/ -- code and data for fig. 2
      multiple_agents/ -- code and data for fig. 3
      replay_memory/ -- code and data for replay experiments (fig. 1)
      trace_lambda/ -- code and data for lambda experiments (no figure)

   test_scripts/
      benchmark.sh -- test script we used to benchmark learners during development
                      run with 'make test' in root dir
      combine_csvs.py -- glues together logfiles for analysis
      cumulative_plot.py -- multithreaded testbed for fig 3
      features_learning_rates.py -- multithreaded testbed for features and learning rates
      learning_speeds.py -- testbed for learning speeds
      replay_statistics.py -- replay memory analysis script
      sarsa_lambda_stats.py -- SARSA(lambda) analysis script

   src/
      __init__.py -- duh
      agents.py -- logic for reinforcement learning algorithms
      constants.py -- constants
      eligibility_tracer.py -- sarsa lambda eligibility trace
      feature_extractors.py -- featuresets
      game_engine.py -- breakout implementation, control loop
      replay_memory.py -- Q-learning replay memory
      utils.py -- utility ops: matrix operations, vector arithmatic, etc
        

==== EXAMPLE USAGE

run some benchmarks:
$ make test

run a breakout game and play it for yourself:
$ python main.py -p human -d -b 50

train a Q-learning agent on 500 games:
$ python main.py -p linearQ -b 500 -e 0.3 -wr myModel.model

test that agent, watch it play, and print out stats as you go
$ python main.py -p linearQ -b 500 -e 0.0 -d -rd myModel.model -csv